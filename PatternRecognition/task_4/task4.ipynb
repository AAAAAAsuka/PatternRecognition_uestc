{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mW:\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_importer_cache\u001b[1;34m(cls, path)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'W:\\\\Anaconda\\\\lib\\\\site-packages\\\\torch\\\\utils\\\\data\\\\_utils'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fbef1a597c04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Anaconda\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__config__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__future__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterableDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConcatDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mChainDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSubset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDistributedSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_worker_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIterableDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSampler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchSampler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mT_co\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'T_co'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcovariant\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mW:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mworker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignal_handling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mW:\\Anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mW:\\Anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mW:\\Anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "\u001b[1;32mW:\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32mW:\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32mW:\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_importer_cache\u001b[1;34m(cls, path)\u001b[0m\n",
      "\u001b[1;32mW:\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_hooks\u001b[1;34m(cls, path)\u001b[0m\n",
      "\u001b[1;32mW:\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mpath_hook_for_FileFinder\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;32mW:\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_isdir\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;32mW:\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_is_mode_type\u001b[1;34m(path, mode)\u001b[0m\n",
      "\u001b[1;32mW:\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.decomposition import PCA\n",
    "from torchvision.models import resnet18, resnet34, resnet50, resnet101\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from skimage import io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "num_classes = 2\n",
    "input_size = 224\n",
    "num_epochs = 1\n",
    "trainset_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'data/test/test/'\n",
    "file_list = os.listdir(path)\n",
    " \n",
    "for file in file_list:\n",
    "    # 补0 10表示补0后名字共10位\n",
    "    filename = file.zfill(9)\n",
    "    # print(filename)\n",
    "    new_name = ''.join(filename)\n",
    "    os.rename(path + '\\\\' + file, path + '\\\\' + new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('label.json','r',encoding='utf8')as fp:\n",
    "    json_data = json.load(fp)\n",
    "test_label = []\n",
    "for i in range(1047):\n",
    "    test_label.append(int(json_data['data{}'.format(i)][-2:])) # pos 120 neg 300\n",
    "test_label = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label[test_label==-1] = 0\n",
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img=io.imread('data/test/test/00001.jpg')\n",
    "io.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform_norm = {\n",
    "    'norm': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "}\n",
    "norm_data = ImageFolder(root='data/train/', transform=data_transform_norm['norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_matrix = []\n",
    "for i in range(len(norm_data)):\n",
    "    norm_matrix.append(np.array(norm_data[i][0]))\n",
    "norm_matrix = np.array(norm_matrix)\n",
    "norm_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_var(norm_matrix):\n",
    "    mean = np.mean(norm_matrix,(0,2,3))\n",
    "    std = np.std(norm_matrix,(0,2,3))\n",
    "    return mean, std\n",
    "train_mean, train_var = get_mean_var(norm_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = {\n",
    "    'train':transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor()\n",
    "#         ,\n",
    "#         transforms.Normalize(train_mean, train_var)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "#         ,\n",
    "#         transforms.Normalize(train_mean, train_var)\n",
    "    ])\n",
    "}\n",
    "train_data = ImageFolder(root='data/train/', transform=data_transform['train'])\n",
    "\n",
    "train_size = int(0.8 * len(train_data))\n",
    "val_size = len(train_data) - train_size\n",
    "train_set, val_set = torch.utils.data.random_split(train_data, [train_size, val_size])\n",
    "\n",
    "test_data = ImageFolder(root='data/test/', transform=data_transform['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# nptestx = np.array(test_x).swapaxes(1,3)\n",
    "list(test_data[0])\n",
    "test_x = []\n",
    "train_array = []\n",
    "for i in range(len(test_data)):\n",
    "    test_x.append(test_data[i][0].numpy())\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    train_array.append(train_data[i][0].numpy())\n",
    "train_array = np.array(train_array)\n",
    "    \n",
    "    \n",
    "test_x = torch.tensor(np.array(test_x))\n",
    "test_y = torch.tensor(np.array(test_label),dtype=torch.long)\n",
    "\n",
    "test_data_ = TensorDataset(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_data_, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "loader = {'train':train_loader, 'val':test_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet34(pretrained = True).to(device)\n",
    "# set_parameter_requires_grad(model_ft, feature_extract)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if is_inception and phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "params_to_update = resnet.parameters()\n",
    "optimizer_ft = optim.Adam(params_to_update, lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model_ft, hist = train_model(resnet, \n",
    "                             loader, \n",
    "                             criterion, \n",
    "                             optimizer_ft, \n",
    "                             num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "resnet.eval()\n",
    "all_outputs = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        test_outputs = resnet(inputs)\n",
    "        _, preds = torch.max(test_outputs, 1)\n",
    "        all_outputs = np.concatenate((all_outputs, preds.cpu().numpy()))\n",
    "        \n",
    "\n",
    "# print(np.mean(all_outputs == test_label))\n",
    "\n",
    "all_outputs[all_outputs==0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs[979]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_txt(label,result_txt):\n",
    "    with open(result_txt,\"w\") as w:\n",
    "        for index,result in enumerate(label,1):#label后面的1,代表下标从1开始\n",
    "            if index != len(label):\n",
    "                w.write(str(index)+\" \"+str(int(result))+\"\\n\")\n",
    "            else:\n",
    "                w.write(str(index)+\" \"+str(int(result)))\n",
    "                \n",
    "store_txt(all_outputs,'./task4_resnet101.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_features(width,height,x,savename):\n",
    "    tic=time.time()\n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "    fig.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.95, wspace=0.05, hspace=0.05)\n",
    "    for i in range(width*height):\n",
    "        plt.subplot(height,width, i + 1)\n",
    "        plt.axis('off')\n",
    "        # plt.tight_layout()\n",
    "        img = x[0, i, :, :]\n",
    "        pmin = np.min(img)\n",
    "        pmax = np.max(img)\n",
    "        img = (img - pmin) / (pmax - pmin + 0.000001)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        print(\"{}/{}\".format(i,width*height))\n",
    "    fig.savefig(savename, dpi=100)\n",
    "    fig.clf()\n",
    "    plt.close()\n",
    "    print(\"time:{}\".format(time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 特征脸\n",
    "\n",
    "# 绘图函数\n",
    "def plot_faces(faces):\n",
    "    fig, axes = plt.subplots(6, 6, figsize=(10,10),\n",
    "                            subplot_kw ={'xticks':[], 'yticks':[]},\n",
    "    gridspec_kw = dict(hspace=0.1,wspace=0.1))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(np.array(faces[i]).transpose(1,2,0))\n",
    "        plt.show\n",
    "def plot_faces_pca(faces):\n",
    "    fig, axes = plt.subplots(6, 6, figsize=(10,10),\n",
    "                            subplot_kw ={'xticks':[], 'yticks':[]},\n",
    "    gridspec_kw = dict(hspace=0.1,wspace=0.1))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(faces[i].reshape(224,224),cmap = 'bone')\n",
    "        plt.show\n",
    "# 特征脸\n",
    "\n",
    "unmask_x = train_array[:1100]\n",
    "mask_x = train_array[1100:]\n",
    "def plot_eigenface(data):\n",
    "    pca = PCA()\n",
    "    data = np.mean(data,axis = 1).reshape((len(data), -1))\n",
    "    pca.fit(data)\n",
    "    pca.components_.shape #36*361\n",
    "    plot_faces_pca(pca.components_)\n",
    "plot_eigenface(unmask_x)\n",
    "plot_eigenface(mask_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x[0]\n",
    "io.imshow(np.array(test_x[0]).transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.array(test_x)\n",
    "test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'X:\\\\PatternRecognition\\\\4\\\\data\\\\test\\\\test\\\\00986.jpg'\n",
    "img = Image.open(img_path).convert('RGB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_grad = None\n",
    "def extract(g):\n",
    "    global features_grad\n",
    "    features_grad = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def draw_CAM(model, img_num, save_path, transform=None, visual_heatmap=False):\n",
    "    '''\n",
    "    绘制 Class Activation Map\n",
    "    :param model: 加载好权重的Pytorch model\n",
    "    :param img_path: 测试图片路径\n",
    "    :param save_path: CAM结果保存路径\n",
    "    :param transform: 输入图像预处理方法\n",
    "    :param visual_heatmap: 是否可视化原始heatmap（调用matplotlib）\n",
    "    :return:\n",
    "    '''\n",
    "    # 图像加载&预处理\n",
    "#     img = Image.open(img_path).convert('RGB')\n",
    "#     if transform:\n",
    "#         img = transform(img)\n",
    "#     img = img.unsqueeze(0)\n",
    "    img = test_data[int(img_num)-1][0]\n",
    "    img = img.unsqueeze(0).cuda()\n",
    "    # 获取模型输出的feature/score\n",
    "    model.eval()\n",
    "    def my_forward(model, x):\n",
    "#         print(*list(model.children())[:-2])\n",
    "        mo1 = nn.Sequential(*list(model.children())[:-1])\n",
    "        mo2 = nn.Sequential(*list(model.children())[:-2])\n",
    "        feature1 = mo1(x).view(x.size(0), -1)\n",
    "        feature2 = mo2(x)\n",
    "        output= model.fc(feature1)\n",
    "        return feature2, output\n",
    "\n",
    "    myfeature, myoutput=my_forward(resnet, img)\n",
    "    features = myfeature\n",
    "    \n",
    "    output = myoutput\n",
    "#     output = model.fc(features)\n",
    "#     print(features.shape)\n",
    "    # 为了能读取到中间梯度定义的辅助函数\n",
    "    def extract(g):\n",
    "        global features_grad\n",
    "        features_grad = g\n",
    " \n",
    "    # 预测得分最高的那一类对应的输出score\n",
    "    pred = torch.argmax(output).item()\n",
    "    if pred == 1:\n",
    "        print('masked')\n",
    "    elif pred == 0:\n",
    "        print('unmasked')\n",
    "#     print(pred)\n",
    "    pred_class = output[:, pred]\n",
    " \n",
    "    features.register_hook(extract)\n",
    "    pred_class.backward() # 计算梯度\n",
    " \n",
    "    grads = features_grad   # 获取梯度\n",
    "#     print(grads.shape)\n",
    " \n",
    "    pooled_grads = torch.nn.functional.adaptive_avg_pool2d(grads, (1, 1))\n",
    " \n",
    "    # 此处batch size默认为1，所以去掉了第0维（batch size维）\n",
    "    pooled_grads = pooled_grads[0]\n",
    "    features = features[0]\n",
    "    # 512是最后一层feature的通道数\n",
    "    for i in range(512):\n",
    "        features[i, ...] *= pooled_grads[i, ...]\n",
    " \n",
    "    # 以下部分同Keras版实现\n",
    "    heatmap = features.detach().cpu().numpy()\n",
    "#     print('1', heatmap.shape)\n",
    "    heatmap = np.mean(heatmap, axis=0)\n",
    " \n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "#     print('2', heatmap.shape)\n",
    "#     print(heatmap)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    \n",
    "    heatmap_ = heatmap\n",
    " \n",
    "    # 可视化原始热力图\n",
    "    if visual_heatmap:\n",
    "        plt.matshow(heatmap)\n",
    "        plt.show()\n",
    "        \n",
    "    img_path = '.\\\\data\\\\test\\\\test\\\\{}.jpg'.format(img_num)\n",
    "    save_path = '.\\\\cam_output\\\\cam_output_{}.jpg'.format(img_num)\n",
    "    \n",
    "    img = cv2.imread(img_path)  # 用cv2加载原始图像\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))  # 将热力图的大小调整为与原始图像相同\n",
    "    heatmap = np.uint8(255 * heatmap)  # 将热力图转换为RGB格式\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)  # 将热力图应用于原始图像\n",
    "    superimposed_img = heatmap * 0.4 + img  # 这里的0.4是热力图强度因子\n",
    "    cv2.imwrite(save_path, superimposed_img)  # 将图像保存到硬盘\n",
    "    \n",
    "    return heatmap_\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "heatmap_ = draw_CAM(resnet,'00980', save_path, transform=None, visual_heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(heatmap_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
